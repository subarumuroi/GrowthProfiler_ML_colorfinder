{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = /data/mtp03_20250801_060149.bmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cbe67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse, sys, os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------\n",
    "# DEFAULT CONFIG (edit as needed)\n",
    "# -------------------------------\n",
    "\n",
    "# Fiducial (red/blue checker) detection in HSV\n",
    "HSV_RED1 = ((0, 80, 60), (10, 255, 255))       # lower red\n",
    "HSV_RED2 = ((170, 80, 60), (180, 255, 255))    # upper red\n",
    "HSV_BLUE = ((100, 80, 60), (135, 255, 255))\n",
    "\n",
    "FIDUCIAL_MIN_AREA = 200\n",
    "FIDUCIAL_MAX_CANDIDATES = 20\n",
    "\n",
    "# Blob detector (center spots) — permissive (rounded squares)\n",
    "BLOB_MIN_AREA = 200\n",
    "BLOB_MAX_AREA = 8000\n",
    "BLOB_MIN_CIRCULARITY = 0.08\n",
    "BLOB_MIN_INERTIA = 0.08\n",
    "BLOB_MIN_CONVEXITY = 0.2\n",
    "\n",
    "N_COLS = 12\n",
    "N_ROWS = 8\n",
    "\n",
    "# Inner ROI (ellipse) as fraction of cell size\n",
    "INNER_SCALE_X = 0.45\n",
    "INNER_SCALE_Y = 0.45\n",
    "\n",
    "# Glare rejection: drop top X percentile\n",
    "DEFAULT_GLARE_DROP_TOP_PCT = 5.0\n",
    "\n",
    "# ---------------------------------\n",
    "# Utility functions\n",
    "# ---------------------------------\n",
    "\n",
    "def imread(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(path)\n",
    "    return img\n",
    "\n",
    "def order_corners(pts):\n",
    "    pts = np.array(pts, dtype=np.float32)\n",
    "    s = pts.sum(axis=1)\n",
    "    diff = np.diff(pts, axis=1).reshape(-1)\n",
    "    rect = np.zeros((4,2), np.float32)\n",
    "    rect[0] = pts[np.argmin(s)]       # TL\n",
    "    rect[2] = pts[np.argmax(s)]       # BR\n",
    "    rect[1] = pts[np.argmin(diff)]    # TR\n",
    "    rect[3] = pts[np.argmax(diff)]    # BL\n",
    "    return rect\n",
    "\n",
    "def get_hsv_masks(bgr):\n",
    "    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "    red1 = cv2.inRange(hsv, np.array(HSV_RED1[0]), np.array(HSV_RED1[1]))\n",
    "    red2 = cv2.inRange(hsv, np.array(HSV_RED2[0]), np.array(HSV_RED2[1]))\n",
    "    red = cv2.bitwise_or(red1, red2)\n",
    "    blue = cv2.inRange(hsv, np.array(HSV_BLUE[0]), np.array(HSV_BLUE[1]))\n",
    "    return red, blue\n",
    "\n",
    "def find_fiducial_corners(bgr, use_overlap=False, debug=False):\n",
    "    \"\"\"Return 4 points [TL, TR, BR, BL] if found, else None.\"\"\"\n",
    "    h, w = bgr.shape[:2]\n",
    "    red, blue = get_hsv_masks(bgr)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    if use_overlap:\n",
    "        cand = cv2.bitwise_and(cv2.dilate(red,kernel), cv2.dilate(blue,kernel))\n",
    "    else:\n",
    "        cand = cv2.dilate(cv2.bitwise_or(red,blue), kernel)\n",
    "\n",
    "    cnts, _ = cv2.findContours(cand, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    picks = []\n",
    "    for c in cnts:\n",
    "        a = cv2.contourArea(c)\n",
    "        if a < FIDUCIAL_MIN_AREA: \n",
    "            continue\n",
    "        x,y,wc,hc = cv2.boundingRect(c)\n",
    "        cx, cy = x+wc/2, y+hc/2\n",
    "        picks.append((a, (cx,cy)))\n",
    "    picks.sort(key=lambda x: -x[0])\n",
    "    picks = picks[:FIDUCIAL_MAX_CANDIDATES]\n",
    "    if not picks:\n",
    "        return None\n",
    "\n",
    "    # choose closest to four image corners\n",
    "    targets = [(0,0), (w-1,0), (w-1,h-1), (0,h-1)]\n",
    "    chosen = []\n",
    "    pool = picks[:]\n",
    "    for tx,ty in targets:\n",
    "        if not pool: return None\n",
    "        d = [np.hypot(cx-tx, cy-ty) for _,(cx,cy) in pool]\n",
    "        ix = int(np.argmin(d))\n",
    "        chosen.append(pool.pop(ix)[1])\n",
    "\n",
    "    return order_corners(chosen)\n",
    "\n",
    "def warp_by_corners(bgr, corners):\n",
    "    h, w = bgr.shape[:2]\n",
    "    dst = np.array([[0,0],[w-1,0],[w-1,h-1],[0,h-1]], dtype=np.float32)\n",
    "    M = cv2.getPerspectiveTransform(order_corners(corners), dst)\n",
    "    out = cv2.warpPerspective(bgr, M, (w,h), flags=cv2.INTER_LINEAR)\n",
    "    return out\n",
    "\n",
    "def detect_plate_rectangle(bgr):\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (9,9), 0)\n",
    "    edges = cv2.Canny(blur, 50, 150)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=200, minLineLength=450, maxLineGap=30)\n",
    "    if lines is None: \n",
    "        return None\n",
    "    lines = lines.reshape(-1,4)\n",
    "\n",
    "    def ang(l): \n",
    "        x1,y1,x2,y2 = l; return np.degrees(np.arctan2(y2-y1, x2-x1))\n",
    "    horiz = [l for l in lines if abs(ang(l)) < 15]\n",
    "    vert  = [l for l in lines if abs(ang(l)) > 75]\n",
    "    if len(horiz) < 2 or len(vert) < 2: \n",
    "        return None\n",
    "\n",
    "    def length(l): \n",
    "        x1,y1,x2,y2 = l; return np.hypot(x2-x1, y2-y1)\n",
    "    horiz.sort(key=length, reverse=True)\n",
    "    vert.sort(key=length, reverse=True)\n",
    "    horiz = horiz[:10]; vert = vert[:10]\n",
    "\n",
    "    xs = [(min(l[0],l[2]), max(l[0],l[2]), l) for l in vert]\n",
    "    ys = [(min(l[1],l[3]), max(l[1],l[3]), l) for l in horiz]\n",
    "    left  = min(xs, key=lambda t:t[0])[2]\n",
    "    right = max(xs, key=lambda t:t[1])[2]\n",
    "    top   = min(ys, key=lambda t:t[0])[2]\n",
    "    bot   = max(ys, key=lambda t:t[1])[2]\n",
    "\n",
    "    def line(p1,p2):\n",
    "        x1,y1 = p1; x2,y2 = p2\n",
    "        A = y2-y1; B = x1-x2; C = A*x1 + B*y1\n",
    "        return A,B,C\n",
    "    def inter(L1,L2):\n",
    "        A1,B1,C1 = L1; A2,B2,C2 = L2\n",
    "        d = A1*B2 - A2*B1\n",
    "        if abs(d) < 1e-6: return None\n",
    "        x = (C1*B2 - C2*B1)/d\n",
    "        y = (A1*C2 - A2*C1)/d\n",
    "        return (x,y)\n",
    "\n",
    "    L_left  = line((left[0],left[1]), (left[2],left[3]))\n",
    "    L_right = line((right[0],right[1]), (right[2],right[3]))\n",
    "    L_top   = line((top[0],top[1]), (top[2],top[3]))\n",
    "    L_bot   = line((bot[0],bot[1]), (bot[2],bot[3]))\n",
    "\n",
    "    tl = inter(L_left, L_top)\n",
    "    tr = inter(L_right,L_top)\n",
    "    br = inter(L_right,L_bot)\n",
    "    bl = inter(L_left, L_bot)\n",
    "    if None in (tl,tr,br,bl): \n",
    "        return None\n",
    "    return order_corners([tl,tr,br,bl])\n",
    "\n",
    "def build_blob_detector():\n",
    "    p = cv2.SimpleBlobDetector_Params()\n",
    "    p.filterByArea = True; p.minArea = BLOB_MIN_AREA; p.maxArea = BLOB_MAX_AREA\n",
    "    p.filterByCircularity = True; p.minCircularity = BLOB_MIN_CIRCULARITY\n",
    "    p.filterByInertia = True; p.minInertiaRatio = BLOB_MIN_INERTIA\n",
    "    p.filterByConvexity = True; p.minConvexity = BLOB_MIN_CONVEXITY\n",
    "    p.filterByColor = True; p.blobColor = 255  # light blobs on dark\n",
    "    return cv2.SimpleBlobDetector_create(p)\n",
    "\n",
    "def detect_centers_blob(rectified_bgr):\n",
    "    gray = cv2.cvtColor(rectified_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (25,25)))\n",
    "    norm = cv2.normalize(tophat, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    blur = cv2.GaussianBlur(norm, (7,7), 0)\n",
    "    det = build_blob_detector()\n",
    "    kps = det.detect(blur)\n",
    "    pts = np.array([kp.pt for kp in kps], dtype=np.float32) if kps else np.empty((0,2), np.float32)\n",
    "    return pts\n",
    "\n",
    "def kmeans_sorted_1d(values, K):\n",
    "    Z = np.float32(values.reshape(-1,1))\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.1)\n",
    "    attempts = 10\n",
    "    compactness, labels, centers = cv2.kmeans(Z, K, None, criteria, attempts, cv2.KMEANS_PP_CENTERS)\n",
    "    centers = centers.reshape(-1)\n",
    "    order = np.argsort(centers)\n",
    "    lab_map = {old:new for new,old in enumerate(order)}\n",
    "    labels_sorted = np.vectorize(lab_map.get)(labels.reshape(-1))\n",
    "    return centers[order], labels_sorted\n",
    "\n",
    "def assign_grid_from_points(pts, n_cols, n_rows):\n",
    "    xs = pts[:,0]; ys = pts[:,1]\n",
    "    cx, lx = kmeans_sorted_1d(xs, n_cols)\n",
    "    cy, ly = kmeans_sorted_1d(ys, n_rows)\n",
    "    grid = [[None for _ in range(n_cols)] for _ in range(n_rows)]\n",
    "    for (x,y), ix, iy in zip(pts, lx, ly):\n",
    "        grid[iy][ix] = (float(x), float(y))\n",
    "    # interpolate any missing\n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            if grid[r][c] is None:\n",
    "                row_vals = [(cc, grid[r][cc]) for cc in range(n_cols) if grid[r][cc] is not None]\n",
    "                col_vals = [(rr, grid[rr][c]) for rr in range(n_rows) if grid[rr][c] is not None]\n",
    "                x_est = np.interp(c, [cc for cc,_ in row_vals], [v[0] for _,v in row_vals]) if len(row_vals)>=2 else None\n",
    "                y_est = np.interp(r, [rr for rr,_ in col_vals], [v[1] for _,v in col_vals]) if len(col_vals)>=2 else None\n",
    "                if x_est is not None and y_est is not None:\n",
    "                    grid[r][c] = (float(x_est), float(y_est))\n",
    "    return grid, cx, cy\n",
    "\n",
    "def robust_intensity_L(bgr, center, dx, dy, drop_top_pct):\n",
    "    x, y = center\n",
    "    rx = dx * INNER_SCALE_X\n",
    "    ry = dy * INNER_SCALE_Y\n",
    "    h, w = bgr.shape[:2]\n",
    "    mask = np.zeros((h,w), np.uint8)\n",
    "    cv2.ellipse(mask, (int(round(x)), int(round(y))), (int(round(rx)), int(round(ry))), 0, 0, 360, 255, -1)\n",
    "    L = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)[:,:,0].astype(np.float32)\n",
    "    vals = L[mask==255]\n",
    "    if vals.size == 0: return np.nan\n",
    "    if drop_top_pct > 0:\n",
    "        cutoff = np.percentile(vals, 100 - drop_top_pct)\n",
    "        vals = vals[vals <= cutoff]\n",
    "        if vals.size == 0: return np.nan\n",
    "    return float(np.median(vals))\n",
    "\n",
    "# ---------------------------------\n",
    "# Main pipeline\n",
    "# ---------------------------------\n",
    "\n",
    "def process(image_path, out_csv, show=False, debug=False, method=\"auto\", drop_top_pct=DEFAULT_GLARE_DROP_TOP_PCT):\n",
    "    bgr = imread(image_path)\n",
    "    H0, W0 = bgr.shape[:2]\n",
    "\n",
    "    rectified = None\n",
    "    used_rect = None\n",
    "\n",
    "    if method in (\"auto\",\"fiducial\"):\n",
    "        # Try fiducial-based (first with overlap mask, then relaxed OR mask)\n",
    "        for overlap in (True, False):\n",
    "            corners = find_fiducial_corners(bgr, use_overlap=overlap, debug=debug)\n",
    "            if corners is not None:\n",
    "                rectified = warp_by_corners(bgr, corners)\n",
    "                used_rect = \"fiducials\"\n",
    "                break\n",
    "\n",
    "    if rectified is None and method in (\"auto\",\"lines\"):\n",
    "        # Try plate rectangle detection\n",
    "        corners = detect_plate_rectangle(bgr)\n",
    "        if corners is not None:\n",
    "            # Warp to a rectangle sized by detected quad\n",
    "            tl,tr,br,bl = corners\n",
    "            width_top = np.hypot(*(tr - tl))\n",
    "            width_bot = np.hypot(*(br - bl))\n",
    "            height_left = np.hypot(*(bl - tl))\n",
    "            height_right= np.hypot(*(br - tr))\n",
    "            W = int(max(width_top, width_bot))\n",
    "            H = int(max(height_left, height_right))\n",
    "            dst = np.array([[0,0],[W-1,0],[W-1,H-1],[0,H-1]], dtype=np.float32)\n",
    "            M = cv2.getPerspectiveTransform(corners, dst)\n",
    "            rectified = cv2.warpPerspective(bgr, M, (W,H))\n",
    "            used_rect = \"lines\"\n",
    "\n",
    "    # If still None, carry on without rectification\n",
    "    working = rectified if rectified is not None else bgr\n",
    "    if debug:\n",
    "        print(f\"Rectification: {used_rect if used_rect else 'none'}; working size = {working.shape[1]}x{working.shape[0]}\")\n",
    "\n",
    "    # Try to detect centers; if too few, we’ll fall back to uniform grid\n",
    "    pts = detect_centers_blob(working)\n",
    "    use_uniform_grid = (pts.shape[0] < (N_ROWS * N_COLS * 0.6))  # permissive; require ~60% found\n",
    "\n",
    "    if not use_uniform_grid:\n",
    "        grid, cx, cy = assign_grid_from_points(pts, N_COLS, N_ROWS)\n",
    "        dx = float(np.median(np.diff(cx))) if len(cx)>1 else working.shape[1]/N_COLS\n",
    "        dy = float(np.median(np.diff(cy))) if len(cy)>1 else working.shape[0]/N_ROWS\n",
    "    else:\n",
    "        # Even subdivision\n",
    "        H, W = working.shape[:2]\n",
    "        dx = W / N_COLS\n",
    "        dy = H / N_ROWS\n",
    "        grid = [[((c+0.5)*dx, (r+0.5)*dy) for c in range(N_COLS)] for r in range(N_ROWS)]\n",
    "\n",
    "    # Measure\n",
    "    records = []\n",
    "    for r in range(N_ROWS):\n",
    "        for c in range(N_COLS):\n",
    "            center = grid[r][c]\n",
    "            if center is None:\n",
    "                val = np.nan\n",
    "            else:\n",
    "                val = robust_intensity_L(working, center, dx, dy, drop_top_pct)\n",
    "            records.append({\n",
    "                \"row\": chr(ord('A')+r),\n",
    "                \"col\": c+1,\n",
    "                \"well\": f\"{chr(ord('A')+r)}{c+1}\",\n",
    "                \"intensity_L\": val\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "\n",
    "    # Print targets\n",
    "    mask = df[\"row\"].isin([\"D\",\"E\"]) & df[\"col\"].between(3,10)\n",
    "    targets = df.loc[mask].copy()\n",
    "    print(\"Targets (D3..D10, E3..E10):\")\n",
    "    print(targets.to_string(index=False))\n",
    "    print(f\"\\nSaved all wells to: {out_csv}\")\n",
    "\n",
    "    # Optional visualization\n",
    "    if show or debug:\n",
    "        vis = working.copy()\n",
    "        # draw ellipses + labels\n",
    "        for r in range(N_ROWS):\n",
    "            for c in range(N_COLS):\n",
    "                center = grid[r][c]\n",
    "                if center is None: continue\n",
    "                x,y = map(int, center)\n",
    "                rx = int(dx*INNER_SCALE_X); ry = int(dy*INNER_SCALE_Y)\n",
    "                cv2.ellipse(vis, (x,y), (rx,ry), 0, 0, 360, (255,0,0), 2)\n",
    "                cv2.putText(vis, f\"{chr(65+r)}{c+1}\", (x-12,y+4), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,255,0), 1, cv2.LINE_AA)\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.figure(figsize=(10,10))\n",
    "            plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
    "            title = \"Rectified\" if rectified is not None else \"Unrectified\"\n",
    "            plt.title(f\"{title} grid & measurement ROIs\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return df, targets\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"96-well plate color intensity extractor\")\n",
    "    ap.add_argument(\"--image\", required=True)\n",
    "    ap.add_argument(\"--out\", default=\"well_intensities.csv\")\n",
    "    ap.add_argument(\"--method\", choices=[\"auto\",\"fiducial\",\"lines\",\"grid\"], default=\"auto\",\n",
    "                    help=\"auto=fiducials→lines→grid; grid=just subdivide\")\n",
    "    ap.add_argument(\"--drop-top\", type=float, default=DEFAULT_GLARE_DROP_TOP_PCT,\n",
    "                    help=\"glare trimming: drop top percentile within ROI\")\n",
    "    ap.add_argument(\"--show\", action=\"store_true\")\n",
    "    ap.add_argument(\"--debug\", action=\"store_true\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    global DEFAULT_GLARE_DROP_TOP_PCT\n",
    "    DEFAULT_GLARE_DROP_TOP_PCT = args.drop_top\n",
    "\n",
    "    if args.method == \"grid\":\n",
    "        # force no rectification + uniform grid\n",
    "        df, targets = process(args.image, args.out, show=args.show, debug=args.debug, method=\"lines\", drop_top_pct=args.drop_top)\n",
    "    else:\n",
    "        df, targets = process(args.image, args.out, show=args.show, debug=args.debug, method=args.method, drop_top_pct=args.drop_top)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
